{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/m5281004/time-series-prediction/blob/main/optuna/optuna_1%E6%97%A5%E3%81%94%E3%81%A8%E5%87%BA%E5%8A%9B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRe9vL3txllf",
        "outputId": "442937e8-13ca-4316-efe3-99fae0496aed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#  prophetによる予測プログラムのパラメータ改善\n",
        "#  出力値は最良のRMSEを得た場合のcsvとpngとRMSEとRMSE/停止水蒸気量\n",
        "#  計算時間がかかりすぎるためパラメータ変更：30分間隔出力から１日間隔出力に変更。\n",
        "#　　　非常に長くセッションが落ちてしまうので一日ごとに実行する\n",
        "\n",
        "#https://qiita.com/dcm_shimadas/items/8f049c4a258f0fbbfe23  <-  optuna参考ページ\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive/Colab Notebooks/forecast/optuna_2')\n",
        "\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "from matplotlib import pyplot as plt\n",
        "from prophet import Prophet\n",
        "from sklearn.metrics import mean_squared_error\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlwHuF47Pu-Z",
        "outputId": "c49a8f7a-9959-4e4e-8456-6bb2d9691c21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-3.4.0-py3-none-any.whl (409 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.6/409.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.12.0-py3-none-any.whl (226 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.0/226.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.22)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n",
            "Installing collected packages: Mako, colorlog, alembic, optuna\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna\n",
        "import optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8R9jR1x4SBUp"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhiN18ynIyCK"
      },
      "outputs": [],
      "source": [
        "# Prophetの出力をミュート\n",
        "import logging\n",
        "logging.getLogger(\"prophet\").setLevel(logging.ERROR)\n",
        "logging.getLogger(\"cmdstanpy\").setLevel(logging.ERROR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYegRGfNFDaQ"
      },
      "outputs": [],
      "source": [
        "#ファイル読み込み\n",
        "data_tmp = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/forecast/001_segment_data_stop_judge/15T_20151113_20170411.csv',\n",
        "                    index_col = 'date_time',\n",
        "                    parse_dates = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pGX5HuCE2Dc",
        "outputId": "fe884aca-0c5c-4776-ff8b-ea97ad363884"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "75745\n",
            "91009\n"
          ]
        }
      ],
      "source": [
        "print(data_tmp.index.get_loc('2016-08-02 19:55:00'))\n",
        "print(data_tmp.index.get_loc('2016-09-24 19:55:00'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_tmp.index.get_loc('2016-08-04 19:55:00') - data_tmp.index.get_loc('2016-08-03 19:55:00')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hobc9Kn1xaR",
        "outputId": "2757cede-dae3-4f8d-d501-80058363d40c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "288"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ee5-15wtkcCg"
      },
      "outputs": [],
      "source": [
        "# 変数の定義 学習粒度と予測対象期間は色々値を変えてみる(リストにしてループで回すのが良さそう)\n",
        "learning_frequency = 60 #学習粒度(分) 5と30は実施済み [5,10,30,60,120]\n",
        "learning_time = 20 # 学習期間　20日\n",
        "prediction_time = 7 # 予測対象期間　7日 ここも値を変える"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "day_number = 5"
      ],
      "metadata": {
        "id": "VFxrNJ1h2OWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#出力用のフォルダを作る\n",
        "well = '15T_20151113_20170411'\n",
        "os.makedirs('learn_freq='+str(learning_frequency)+', prediction='+str(prediction_time)+'/008_pred_csv01/' , exist_ok=True)\n",
        "os.makedirs('learn_freq='+str(learning_frequency)+', prediction='+str(prediction_time)+'/008_pred_png01/' , exist_ok=True)\n",
        "os.makedirs('learn_freq='+str(learning_frequency)+', prediction='+str(prediction_time)+'/008_pred_rmse01/' , exist_ok=True)\n",
        "os.makedirs('learn_freq='+str(learning_frequency)+', prediction='+str(prediction_time)+'/008_pred_parameter01/' , exist_ok=True)\n",
        "\n",
        "# 停止水蒸気量算出\n",
        "start_time        = data_tmp.index[75745+288*day_number]\n",
        "end_time          = start_time + dt.timedelta(days = 20)\n",
        "data_for_stop     = data_tmp[start_time:end_time]\n",
        "steamvol_for_stop = data_for_stop['steamvol'].mean()*(2/3)\n",
        "end_data          = data_tmp.index[91009]\n",
        "data_start_time   = start_time.strftime('%Y%m%d%H%M%S')\n",
        "data_end_time     = end_data.strftime('%Y%m%d%H%M%S')\n",
        "\n",
        "# 出力フォルダ作成 # このへんmkdirs(, exist_ok = True) あたりを使用するとすっきりする（途中ディレクトリも作ってくれる）\n",
        "#os.makedirs('learn_freq='+str(learning_frequency)+', prediction='+str(prediction_time)+'/008_pred_csv01/'+ well + '/' + data_start_time + '_' + data_end_time , exist_ok=True)\n",
        "#os.makedirs('learn_freq='+str(learning_frequency)+', prediction='+str(prediction_time)+'/008_pred_png01/'+ well + '/' + data_start_time + '_' + data_end_time , exist_ok=True)\n",
        "#os.makedirs('learn_freq='+str(learning_frequency)+', prediction='+str(prediction_time)+'/008_pred_rmse01/'+ well + '/' + data_start_time + '_' + data_end_time , exist_ok=True)\n",
        "#os.makedirs('learn_freq='+str(learning_frequency)+', prediction='+str(prediction_time)+'/008_pred_parameter01/'+ well + '/' + data_start_time + '_' + data_end_time , exist_ok=True)\n",
        "\n",
        "#pathをとっておく\n",
        "csv_path = 'learn_freq='+str(learning_frequency)+', prediction='+str(prediction_time)+'/008_pred_csv01/'\n",
        "png_path = 'learn_freq='+str(learning_frequency)+', prediction='+str(prediction_time)+'/008_pred_png01/'\n",
        "rmse_path = 'learn_freq='+str(learning_frequency)+', prediction='+str(prediction_time)+'/008_pred_rmse01/'\n",
        "parameter_path = 'learn_freq='+str(learning_frequency)+', prediction='+str(prediction_time)+'/008_pred_parameter01/'\n",
        "\n",
        "# 学習、予測の日付時刻の取得\n",
        "start_date_time = data_tmp.index[75745+288*day_number] # 学習開始\n",
        "end_date_time = start_date_time + dt.timedelta(days = learning_time) # 学習終了\n",
        "prediction_start_date_time = end_date_time + dt.timedelta(minutes = learning_frequency) # 予測開始（学習が終了した後学習粒度の分だけ経ったら開始）\n",
        "prediction_end_date_time = prediction_start_date_time + dt.timedelta(days = prediction_time) # 予測終了\n",
        "\n",
        "# 24時間ごとにシフトさせて予測\n",
        "prediction_start_date_time_list = []\n",
        "rmse_list = []\n",
        "thifted_time = 24\n",
        "counter = 1\n",
        "\n",
        "start_date_time = data_tmp.index[75745+288*day_number]\n",
        "end_date_time = start_date_time + dt.timedelta(days = learning_time)\n",
        "start_date_time_str = str(start_date_time.strftime('%Y%m%d%H%M%S'))\n",
        "end_date_time_str = str(end_date_time.strftime('%Y%m%d%H%M%S'))\n",
        "\n",
        "# 予測期間\n",
        "prediction_start_date_time = end_date_time + dt.timedelta(minutes = learning_frequency)\n",
        "prediction_end_date_time = prediction_start_date_time + dt.timedelta(days = prediction_time)\n",
        "\n",
        "prediction_start_date_time_str = str(prediction_start_date_time.strftime('%Y%m%d%H%M%S'))\n",
        "prediction_end_date_time_str   = str(prediction_end_date_time.strftime('%Y%m%d%H%M%S'))\n",
        "print(\" ** \", well, \" の \", start_date_time_str, \" から \", end_date_time_str, \" までを学習します ** \")\n",
        "print(\" ** \", well, \" の \", prediction_start_date_time_str, \" から \", prediction_end_date_time_str, \" までを予測します ** \")\n",
        "\n",
        "# 学習期間→train, 予測期間→test\n",
        "train = data_tmp[start_date_time:end_date_time]\n",
        "train = train.asfreq(str(learning_frequency)+'min') #学習粒度でリサンプリング\n",
        "test = data_tmp[prediction_start_date_time:prediction_end_date_time]\n",
        "test_length = len(test)\n",
        "\n",
        "train.reset_index(inplace = True)\n",
        "test.reset_index(inplace = True)\n",
        "\n",
        "train = train.rename(columns = {'date_time':'ds','steamvol':'y'})\n",
        "test  = test.rename( columns = {'date_time':'ds','steamvol':'y'})\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PZn9I4SLqWw",
        "outputId": "6abc76b7-2f0c-4490-91c1-71eaf01710ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " **  15T_20151113_20170411  の  20160807195500  から  20160827195500  までを学習します ** \n",
            " **  15T_20151113_20170411  の  20160827205500  から  20160903205500  までを予測します ** \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Prophetによる予測\n",
        "#ここからパラメータのチューニング\n",
        "#ーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーー\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        #'uncertainty_samples' : trial.suggest_int('uncertainty_samples', 100, 1000, 450),\n",
        "        'changepoint_range' : trial.suggest_discrete_uniform('changepoint_range',0.8,0.95,0.001),\n",
        "        'n_changepoints' : trial.suggest_int('n_changepoints',20,35),\n",
        "        'changepoint_prior_scale' : trial.suggest_discrete_uniform('changepoint_prior_scale',0.001,0.5,0.001),\n",
        "        'seasonality_prior_scale' : trial.suggest_discrete_uniform('seasonality_prior_scale',1,25,0.5),\n",
        "        'seasonality_mode' : trial.suggest_categorical('seasonality_mode',['additive', 'multiplicative'])\n",
        "        }\n",
        "\n",
        "    tss = TimeSeriesSplit(test_size = 5)\n",
        "\n",
        "    cv_mse = []\n",
        "\n",
        "    for fold, (train_index, valid_index) in enumerate(tss.split(train)):\n",
        "        train_data = train.iloc[train_index] #訓練データ\n",
        "        valid_data = train.iloc[valid_index] #検証データ\n",
        "\n",
        "        m = Prophet(**params)\n",
        "\n",
        "        m.fit(train_data)\n",
        "\n",
        "        df_future = m.make_future_dataframe(\n",
        "            periods = len(valid_data),\n",
        "            freq = str(learning_frequency)+'min'\n",
        "        )\n",
        "\n",
        "        df_pred = m.predict(df_future)\n",
        "        preds = df_pred.tail(len(valid_data))\n",
        "\n",
        "        val_mse = mean_squared_error(\n",
        "            valid_data.y,\n",
        "            preds.yhat\n",
        "        )\n",
        "        cv_mse.append(val_mse)\n",
        "\n",
        "    return np.mean(cv_mse)\n",
        "\n",
        "optuna.logging.disable_default_handler()\n",
        "\n",
        "study = optuna.create_study(direction = 'minimize')\n",
        "#n_trialsの値は1000でいいのか\n",
        "study.optimize(\n",
        "    objective,\n",
        "    n_trials = 1000,\n",
        "    n_jobs = -1\n",
        "    )"
      ],
      "metadata": {
        "id": "rNL6sg_BLQXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(study.best_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TD96kxHGN6Mv",
        "outputId": "1af5126d-5282-4c67-8718-69863647a36c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'changepoint_range': 0.8580000000000001, 'n_changepoints': 25, 'changepoint_prior_scale': 0.057, 'seasonality_prior_scale': 18.5, 'seasonality_mode': 'additive'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "1c74e55e-bea7-460e-f5bc-5756f6ab91c1",
        "id": "oUusADseeZLO"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ** 2日間のRMSEは、 0.208  でした **  \n",
            " ** plot :  learn_freq=60, prediction=7/008_pred_png01/15T_20151113_20170411/20160806195500_20160924195500/20160826205500  .png を書き出しました ** \n",
            "============================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x500 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "\n",
        "#ーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーー\n",
        "\n",
        "#データフレームを作る(ベストパラメータを保存するため)\n",
        "#df_best_parameter = pd.DataFrame()\n",
        "#df_best_parameter['paramater_name'] = ['changepoint_range', 'n_changepoints','changepoint_prior_scale','seasonality_prior_scale','seasonality_mode']\n",
        "#df_best_parameter = df_best_parameter.set_index('paramater_name')\n",
        "\n",
        "parameter_list = pd.DataFrame()\n",
        "parameter_list['best_parameter'] = study.best_params\n",
        "parameter_list.to_csv(parameter_path + prediction_start_date_time_str + '.csv')\n",
        "\n",
        "model_best = Prophet(**study.best_params)\n",
        "model_best.fit(train)\n",
        "future = model_best.make_future_dataframe(periods = test_length, freq = str(learning_frequency)+'min')\n",
        "pred_best  =  model_best.predict(future)\n",
        "pd.to_datetime(pred_best['ds'])\n",
        "pred_best = pred_best.set_index('ds')\n",
        "\n",
        "merged_data_best = pd.merge(data_tmp,\n",
        "                            pred_best,\n",
        "                            right_index = True,\n",
        "                            left_index = True,\n",
        "                            how = 'inner')\n",
        "\n",
        "merged_data_best = merged_data_best[start_date_time:prediction_end_date_time] # 学習期間も含めた\n",
        "merged_data_best.to_csv(csv_path + prediction_start_date_time_str + '.csv')\n",
        "\n",
        "\n",
        "\n",
        "#\n",
        "# RMSE算出\n",
        "#\n",
        "\n",
        "# 2日後までの 総計RMSE 算出\n",
        "actual_best = merged_data_best['steamvol']\n",
        "pred_data_best = merged_data_best['yhat']\n",
        "RMSE_best = np.sqrt(mean_squared_error(actual_best[0:47], pred_data_best[0:47]))\n",
        "\n",
        "print(\" ** 2日間のRMSEは、\", round(RMSE_best, 3), \" でした **  \")\n",
        "\n",
        "# 1日から7日までの 各日のRMSE 算出\n",
        "days_list = ['1day','2days','3days','4days','5days','6days','7days']\n",
        "rmse_list = []\n",
        "for i in [1,2,3,4,5,6,7]:\n",
        "    start = merged_data_best.index[0] + dt.timedelta(days = 1*(i-1))\n",
        "    end = start + dt.timedelta(days = 1) + dt.timedelta(minutes = learning_frequency)\n",
        "    actual_tmp = merged_data_best['steamvol'][start:end]\n",
        "    pred_data_tmp = merged_data_best['yhat'][start:end]\n",
        "    try:\n",
        "        rmse_tmp = np.sqrt(mean_squared_error(actual_tmp, pred_data_tmp))\n",
        "    except:\n",
        "        rmse_tmp = np.nan\n",
        "    rmse_list.append(rmse_tmp)\n",
        "\n",
        "'''\n",
        "# 比較のためのデフォルト値での予測\n",
        "model_default = Prophet(changepoint_prior_scale = 0.5)\n",
        "model_default.fit(train)\n",
        "future_default  =  model_default.make_future_dataframe(periods = test_length, freq = '60min')\n",
        "pred_default  =  model_default.predict(future_default)\n",
        "pd.to_datetime(pred_default['ds'])\n",
        "pred_default = pred_default.set_index('ds')\n",
        "merged_data_default = pd.merge(data_tmp,pred_default,right_index = True,left_index = True,how = 'inner')\n",
        "merged_data_default = merged_data_default[prediction_start_date_time:prediction_end_date_time]\n",
        "actual_00 = merged_data_default['steamvol']\n",
        "pred_data_00 = merged_data_default['yhat']\n",
        "RMSE_00 = np.sqrt(mean_squared_error(actual_00[0:47], pred_data_00[0:47]))# 一応算出：改善度合いをみるため\n",
        "'''\n",
        "\n",
        "#\n",
        "# プロット\n",
        "#\n",
        "plt.rcParams['figure.figsize'] = (20,5)\n",
        "\n",
        "plt.plot(merged_data_best['steamvol'], # 実測値\n",
        "        color = 'black',\n",
        "        label = 'actual_data')\n",
        "\n",
        "plt.plot(merged_data_best.loc[start_date_time:end_date_time,\n",
        "                            'yhat'], # 学習期間\n",
        "        color = 'cyan',\n",
        "        label = 'Training ')\n",
        "\n",
        "plt.plot(merged_data_best.loc[prediction_start_date_time:prediction_end_date_time,\n",
        "                            'yhat'], # 予測期間\n",
        "        color = 'blue',\n",
        "        label = 'Prediction: best RMSE = ' + str(round(RMSE_best, 5)))\n",
        "\n",
        "plt.axvline(prediction_start_date_time,\n",
        "            color='blue', linestyle='--')\n",
        "\n",
        "# plt.plot(merged_data_default['yhat'],color = 'red',label = 'default RMSE = ' + str(RMSE_00)) # デフォルト（cps=0.5）プロット\n",
        "\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.title(str(well)+'  learning_freq = '+str(learning_frequency)+ 'minutes    prediction_time = ' +str(prediction_time)+'days', loc = \"left\")\n",
        "\n",
        "plt.savefig(png_path + prediction_start_date_time_str + '.png')\n",
        "plt.clf()\n",
        "\n",
        "print(\" ** plot : \", png_path + prediction_start_date_time_str , \" .png を書き出しました ** \")\n",
        "\n",
        "\n",
        "# RMSE出力\n",
        "df_rmse = pd.DataFrame()\n",
        "df_rmse['days'] = days_list\n",
        "df_rmse['RMSE'] = rmse_list\n",
        "df_rmse['normed_RMSE'] = rmse_list/steamvol_for_stop\n",
        "df_rmse = df_rmse.set_index('days')\n",
        "df_rmse = df_rmse.T\n",
        "df_rmse['RMSE_best_total'] = [RMSE_best,RMSE_best/steamvol_for_stop]\n",
        "# df_rmse['RMSE_default_total'] = [RMSE_00,RMSE_00/steamvol_for_stop]\n",
        "df_rmse = df_rmse.T\n",
        "\n",
        "df_rmse.to_csv(rmse_path + prediction_start_date_time_str + '.csv')\n",
        "\n",
        "\n",
        "counter = counter + 1\n",
        "print(\"============================================\")\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}